{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa176a5-a5b2-48aa-ae28-00f21a1a32f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mission\n",
    "\n",
    "## A note on cross-validation/validation\n",
    "\n",
    "This notebook is for learning purposes. It includes two approaches to validation: cross-validating the training data and validating using a separate validation dataset. In practice, you generally will only use one or the other for a given project. \n",
    "\n",
    "Cross-validation is more rigorous, because it maximizes the usage of the training data, but if you have a very large dataset or limited computing resources, it may be better to validate with a separate validation dataset.\n",
    "\n",
    "*   Encoding of categorical features as dummies\n",
    "*   Stratification during data splitting\n",
    "*   Fitting a model\n",
    "*   Using `GridSearchCV` to cross-validate the model and tune the following hyperparameters:  \n",
    "    - `max_depth`  \n",
    "    - `max_features`  \n",
    "    - `min_samples_split`\n",
    "    - `n_estimators`  \n",
    "    - `min_samples_leaf`  \n",
    "*   Model evaluation using precision, recall, and f1 score\n",
    "\n",
    "---\n",
    "\n",
    ">  **Modeling objective:** To predict whether a customer will churn&mdash;a binary classification task.\n",
    "\n",
    "\n",
    ">  **Target variable:** `Exited` column&mdash;0 or 1.  \n",
    "\n",
    ">  **Class balance:** The data is imbalanced 80/20 (not churned/churned), but we will not perform class balancing.\n",
    "\n",
    ">  **Primary evaluation metric:** F1 score.\n",
    "\n",
    ">  **Modeling workflow and model selection:** The champion model will be the model with the best validation F1 score. Only the champion model will be used to predict on the test data. See the annotated decision tree notebook for details and limitations of this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331ccbae-8244-491b-8f0e-04e525054497",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Statements\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "## Scikitlearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score,\\\n",
    "confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Saving models with this module\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5d6398-c9a6-4583-bb00-caca39719a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Description</th>\n",
       "      <th>Possible Values</th>\n",
       "      <th>Best Options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>The number of trees in the forest.</td>\n",
       "      <td>Integer, e.g. 100, 200, 500</td>\n",
       "      <td>100-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_depth</td>\n",
       "      <td>The maximum depth of the trees in the forest.</td>\n",
       "      <td>Integer, e.g. 3, 5, 10</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>The minimum number of samples required to spli...</td>\n",
       "      <td>Integer, e.g. 2, 5, 10</td>\n",
       "      <td>2-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>The minimum number of samples required to be a...</td>\n",
       "      <td>Integer, e.g. 1, 2, 5</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_features</td>\n",
       "      <td>The number of features to consider when lookin...</td>\n",
       "      <td>Integer, \"auto\", \"sqrt\", \"log2\"</td>\n",
       "      <td>\"auto\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>criterion</td>\n",
       "      <td>The function to measure the quality of a split.</td>\n",
       "      <td>\"gini\", \"entropy\"</td>\n",
       "      <td>\"gini\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bootstrap</td>\n",
       "      <td>Whether to bootstrap the samples when building...</td>\n",
       "      <td>Boolean, True, False</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oob_score</td>\n",
       "      <td>Whether to calculate an out-of-bag score.</td>\n",
       "      <td>Boolean, True, False</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter                                        Description  \\\n",
       "0       n_estimators                 The number of trees in the forest.   \n",
       "1          max_depth      The maximum depth of the trees in the forest.   \n",
       "2  min_samples_split  The minimum number of samples required to spli...   \n",
       "3   min_samples_leaf  The minimum number of samples required to be a...   \n",
       "4       max_features  The number of features to consider when lookin...   \n",
       "5          criterion    The function to measure the quality of a split.   \n",
       "6          bootstrap  Whether to bootstrap the samples when building...   \n",
       "7          oob_score          Whether to calculate an out-of-bag score.   \n",
       "\n",
       "                   Possible Values Best Options  \n",
       "0      Integer, e.g. 100, 200, 500     100-1000  \n",
       "1           Integer, e.g. 3, 5, 10         5-10  \n",
       "2           Integer, e.g. 2, 5, 10         2-10  \n",
       "3            Integer, e.g. 1, 2, 5          1-5  \n",
       "4  Integer, \"auto\", \"sqrt\", \"log2\"       \"auto\"  \n",
       "5                \"gini\", \"entropy\"       \"gini\"  \n",
       "6             Boolean, True, False         TRUE  \n",
       "7             Boolean, True, False         TRUE  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Usual parameters to adjust\n",
    "df = pd.read_csv('rfParameters.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07b00d96-f7fd-428a-a917-e09998c2a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## locations:\n",
    "loc1 = '/home/gato/Scripts/DS/MachineLearning/data/churn.csv'\n",
    "loc2 = '/home/gato/Scripts/DS/MachineLearning/data/churnModeling.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73e0aaca-e976-4271-b0cc-e407fb3e4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading data\n",
    "df = pd.read_csv(loc1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51fe3796-56ff-457e-8f85-3b5ed119514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Loyalty</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited   Loyalty  Geography_Germany  \\\n",
       "0               1        101348.88       1  0.047619                  0   \n",
       "1               1        112542.58       0  0.024390                  0   \n",
       "2               0        113931.57       1  0.190476                  0   \n",
       "3               0         93826.63       0  0.025641                  0   \n",
       "4               1         79084.10       0  0.046512                  0   \n",
       "\n",
       "   Geography_Spain  \n",
       "0                0  \n",
       "1                1  \n",
       "2                0  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading data 2\n",
    "## This data was cleaned, checked and get to this stage. On an earlier task\n",
    "df2 = pd.read_csv(loc2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd3389c-45d3-41f7-b91f-971179531279",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary', 'Loyalty',\n",
    "       'Geography_Germany', 'Geography_Spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4208e91f-0115-450d-87df-ae3ea3fcd812",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data\n",
    "y = df2['Exited']\n",
    "X = df2[x_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718a779-1f3c-4ef6-9b0e-894bdc9f2b28",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "### Cross-validated hyperparameter tuning\n",
    "\n",
    "The cross-validation process is the same as it was for the decision tree model. The only difference is that we're tuning more hyperparameters now. The steps are included below as a review. \n",
    "\n",
    "For details on cross-validating with `GridSearchCV`, refer back to the decision tree notebook, or to the [GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) in scikit-learn.\n",
    "\n",
    "1. Instantiate the classifier (and set the `random_state`). \n",
    "\n",
    "2. Create a dictionary of hyperparameters to search over.\n",
    "\n",
    "3. Create a dictionary of scoring metrics to capture. \n",
    "\n",
    "4. Instantiate the `GridSearchCV` object. Pass as arguments:\n",
    "  - The classifier (`rf`)\n",
    "  - The dictionary of hyperparameters to search over (`cv_params`)\n",
    "  - The dictionary of scoring metrics (`scoring`)\n",
    "  - The number of cross-validation folds you want (`cv=5`)\n",
    "  - The scoring metric that you want GridSearch to use when it selects the \"best\" model (i.e., the model that performs best on average over all validation folds) (`refit='f1'`)\n",
    "\n",
    "5. Fit the data (`X_train`, `y_train`) to the `GridSearchCV` object (`rf_cv`).\n",
    "\n",
    "Note that we use the `%%time` magic at the top of the cell. This outputs the final runtime of the cell. (Magic commands, often just called \"magics,\" are commands that are built into IPython to simplify common tasks. They begin with `%` or `%%`.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e8e73-e6ac-4928-abe9-a32bef2d8ae0",
   "metadata": {},
   "source": [
    "### Hyper-parameter grid. \n",
    "Tune five hyper-parameters, \n",
    "- max depth, \n",
    "- min samples leaf, \n",
    "- min samples split, \n",
    "- max features, and \n",
    "- number of estimators. \n",
    "\n",
    "**max depth**, note, `None` is included. This means that one of the options allows the trees to grow without a specific limit on their depth. \n",
    "\n",
    "Instantiate our classifier and assign it a **random state for reproducibility** and specify the metrics the model will capture. \n",
    "\n",
    "**Instantiate the grid search object.** \n",
    "It has two positional arguments, \n",
    "- the classifier and \n",
    "- the parameter grid.\n",
    "\n",
    "Use the scoring metrics specified above and set CV to five. \n",
    "\n",
    "This means the model will be cross-validated using five folds. \n",
    "\n",
    "Lastly, specify **refit equals F1.** This is necessary when we've given multiple scoring metrics because it tells grid search that even though we want to check a few different metrics, the one we care most about is the F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfc392-243c-49f7-bbf2-d176babe8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "cv_params = {'max_depth': [2,3,4,5, None], \n",
    "             'min_samples_leaf': [1,2,3],\n",
    "             'min_samples_split': [2,3,4],\n",
    "             'max_features': [2,3,4],\n",
    "             'n_estimators': [75, 100, 125, 150]\n",
    "             }  \n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "rf_cv = GridSearchCV(rf, cv_params, scoring=scoring, cv=5, refit='f1')\n",
    "\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09067386-efa1-4a19-ae26-4801cad85415",
   "metadata": {},
   "source": [
    "# good news is that there's a method that enables you to save the fit model object to a specified location and then quickly read it back in.\n",
    " \n",
    " **Once you find a model you're happy with**, you don't want to start from scratch every time you open your notebook, and that's where pickling comes in. \n",
    " \n",
    " Pickle is a tool that saves the fit model object to a specified location and then quickly reads it back in. \n",
    " It also allows you to use models that would fit somewhere else without having to train them yourself. Let's pick up where we left off and pickle the model. \n",
    " \n",
    " - First, specify a file path to the directory where the model will be saved. \n",
    " - Then create a `with open()` statement, passing to it the file path plus the name you want to use to save this model, followed by dot pickle. This creates an empty pickle file. The second argument, `wb`, gives permission `to_write` to the file **in binary, which is how pickling works.** Use `as` to assign the return value of open to a local variable named `to_write`. Call `pickle.dump` and pass the fit model object to it. Then, the to_write variable.\n",
    " \n",
    " - In the next cell, read back in the pickled model from where it's saved. The only difference in syntax is using `rb` to specify that we'll be reading binary and using `pickle.load` to assign a new variable, which points to the fit model. Make sure you call this new variable by the same name you used for your fit model above, in this case, `rf_cv`. If you comment out the line of code where you fit the model and the cell where you pickle the model, you can close the notebook, reopen it, and rerun all the cells without having to wait for the model to fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb896d3-f96e-4f82-b6ab-37953652c500",
   "metadata": {},
   "source": [
    "## Pickle  \n",
    "\n",
    "When models take a long time to fit, you don’t want to have to fit them more than once. If your kernel disconnects or you shut down the notebook and lose the cell’s output, you’ll have to refit the model, which can be frustrating and time-consuming. \n",
    "\n",
    "`pickle` is a tool that saves the fit model object to a specified location, then quickly reads it back in. It also allows you to use models that were fit somewhere else, without having to train them yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4113a1-91df-4e7a-b7e7-d3e0d63397fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a path to the folder where you want to save the model\n",
    "path = '/home/gato/Scripts/DS/MachineLearning/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a5623-de3d-45dd-9cb2-96eef53aba57",
   "metadata": {},
   "source": [
    "This step will ***W***rite (i.e., save) the model, in ***B***inary (hence, `wb`), to the folder designated by the above path. In this case, the name of the file we're writing is `rf_cv_model.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306bfa89-2c03-4f7f-bffc-d34616363e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model\n",
    "with open(path+'rf_cv_model.pickle', 'wb') as to_write:\n",
    "    pickle.dump(rf_cv, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a20148-535d-45ac-80a8-18f549915e2a",
   "metadata": {},
   "source": [
    "Once we save the model, we'll never have to re-fit it when we run this notebook. Ideally, we could open the notebook, select \"Run all,\" and the cells would run successfully all the way to the end without any model retraining. \n",
    "\n",
    "For this to happen, we'll need to return to the cell where we defined our grid search and comment out the line where we fit the model. Otherwise, when we re-run the notebook, it would refit the model. \n",
    "\n",
    "Similarly, we'll also need to go back to where we saved the model as a pickle and comment out those lines.  \n",
    "\n",
    "Next, we'll add a new cell that reads in the saved model from the folder we already specified. For this, we'll use `rb` (read binary) and be sure to assign the model to the same variable name as we used above, `rf_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eff5b2b-0b4f-4c06-80b1-e67c67a9e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gato/anaconda3/lib/python3.9/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/gato/anaconda3/lib/python3.9/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Open Read in pickled model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf_cv_model.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m to_read:\n\u001b[0;32m----> 3\u001b[0m     rf_cv \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_read\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:714\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:1418\u001b[0m, in \u001b[0;36msklearn.tree._tree._check_node_ndarray\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    "# Open Read in pickled model\n",
    "with open(path + 'rf_cv_model.pickle', 'rb') as to_read:\n",
    "    rf_cv = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e47f3c-3c1f-4224-9e5c-532e4da27c21",
   "metadata": {},
   "source": [
    "Now everything above is ready to run quickly and without refitting. We can continue by using the model's `best_params_` attribute to check the hyperparameters that had the best average F1 score across all the cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07f71d-48d0-42b9-ad0e-ac308c8dec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a74f65-473e-43b7-90c8-3d91b7b94c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
